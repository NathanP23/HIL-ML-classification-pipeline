# HIL ML Classification Pipeline

A human-in-the-loop machine learning system for automated text classification using progressive few-shot learning. Features interactive workflows for data preparation, model training with OpenAI API, human feedback integration, and bulk classification.

## ğŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- OpenAI API key

### Quick Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd HIL-ML-classification-pipeline
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env file with your OpenAI API key and configuration
   ```

5. **Run the application**
   ```bash
   python main.py
   ```

## âš™ï¸ Configuration

The system uses environment variables for configuration. Copy `.env.example` to `.env` and customize:

- **OPENAI_API_KEY**: Your OpenAI API key
- **COLUMN_MAPPINGS**: JSON mapping of standardized to original column names
- **FILES**: JSON configuration for input data files
- **LABEL_INFO**: JSON definitions of classification categories
- **PROMPTS**: JSON templates for different prompts
- **SYSTEM_PROMPT_TEMPLATE**: Template for system prompts

## ğŸ“‹ Overview

This project provides an interactive text classification system using GPT-4 with progressive few-shot learning. The system processes text documents and classifies them into predefined categories using human-in-the-loop feedback to continuously improve accuracy.

## ğŸ›ï¸ Menu Options

The system provides an interactive menu with the following options:

### Option 1: Run data preparation

**Purpose:** Load, anonymize, and consolidate raw data into a single DataFrame ready for classification.

**Options Available:**
1. **Load from raw Excel files** - Processes original data with full anonymization pipeline
2. **Load from anonymized CSV files** - Uses previously processed and anonymized CSV files

**Functions Called:**
```
core.utils.menu_handlers.run_data_preparation()
â”œâ”€â”€ **Purpose:** Orchestrates the complete data preparation workflow with user choice
â”œâ”€â”€ **Args:** None
â”œâ”€â”€ **Returns:** pd.DataFrame - Consolidated DataFrame ready for classification
â”‚
â”œâ”€â”€ **Option 1 Path:** Load from raw Excel files
â”‚   â”œâ”€â”€ core.data.loader.load_data()
â”‚   â”‚   â”œâ”€â”€ **Purpose:** Load Excel files and apply column mappings
â”‚   â”‚   â”œâ”€â”€ **Args:** None (reads from config.settings.FILES and COLUMN_MAPPINGS)
â”‚   â”‚   â”œâ”€â”€ **Returns:** dict - {"df1": DataFrame, "df2": DataFrame, "df3": DataFrame}
â”‚   â”‚   â””â”€â”€ **Process:** Reads Excel files â†’ Applies column name standardization â†’ Returns mapped DataFrames
â”‚   â”‚
â”‚   â””â”€â”€ core.data.anonymizer.anonymize_data(dfs)
â”‚       â”œâ”€â”€ **Purpose:** Apply anonymization to sensitive data fields
â”‚       â”œâ”€â”€ **Args:** dfs: dict - Dictionary of DataFrames from load_data()
â”‚       â”œâ”€â”€ **Returns:** dict - Same structure with anonymized data
â”‚       â””â”€â”€ **Process:**
â”‚           â”œâ”€â”€ anonymize_national_id(text) - Replace ID numbers with sequential digits
â”‚           â”œâ”€â”€ anonymize_phone_numbers(text) - Standardize phone number format
â”‚           â””â”€â”€ anonymize_names_from_excel(text) - Replace names with placeholders
â”‚
â”œâ”€â”€ **Option 2 Path:** Load from anonymized CSV files
â”‚   â””â”€â”€ core.utils.menu_handlers.load_from_anonymized_csv()
â”‚       â”œâ”€â”€ **Purpose:** Load previously processed anonymized CSV files
â”‚       â”œâ”€â”€ **Args:** None (reads from anonymized/ directory)
â”‚       â”œâ”€â”€ **Returns:** dict - {"df1": DataFrame, "df2": DataFrame, "df3": DataFrame}
â”‚       â””â”€â”€ **Process:** Loads df1_anonymized.csv, df2_anonymized.csv, df3_anonymized.csv
â”‚
â””â”€â”€ core.data.loader.consolidate_data(all_df)
    â”œâ”€â”€ **Purpose:** Merge multiple DataFrames into single consolidated dataset
    â”œâ”€â”€ **Args:** all_df: dict - Anonymized DataFrames
    â”œâ”€â”€ **Returns:** pd.DataFrame - Consolidated DataFrame with deduplication
    â””â”€â”€ **Process:** Extract text_content â†’ Remove invalid entries â†’ Group duplicates â†’ Count appearances
```

**Output Files:**
- **Location:** `anonymized/`
- **Format:** CSV files
- **Files:** `df1_anonymized.csv`, `df2_anonymized.csv`, `df3_anonymized.csv`
- **Content:** Original data with sensitive information anonymized
- **In-Memory:** Consolidated DataFrame with unique text records ready for labeling

---

### Option 2: Run single labeling batch

**Purpose:** Select unlabeled texts, get API predictions, and prepare them for manual correction.

**Execution Flow:**
```
main.py: run_single_labeling_batch()
â”œâ”€â”€ Check if consolidated_df exists in memory
â”‚
â”œâ”€â”€ core.labeling.label_manager: prepare_for_labeling()
â”‚   â”œâ”€â”€ create_stable_ids(): Create MD5 hash IDs from text_content
â”‚   â”œâ”€â”€ load_labeled_ids(): Extract set of already labeled IDs
â”‚   â””â”€â”€ Return DataFrame with hash IDs + labeled_ids set
â”‚
â”œâ”€â”€ core.labeling.batch_processor: process_batch_for_labeling()
â”‚   â”œâ”€â”€ Select batch method (longest/shortest/medium/random)
â”‚   â”‚   â”œâ”€â”€ select_batch_by_length() - Select by longest text length
â”‚   â”‚   â”œâ”€â”€ select_batch_by_shortest() - Select by shortest text length  
â”‚   â”‚   â”œâ”€â”€ select_batch_by_medium_length() - Select by closest to average length
â”‚   â”‚   â”œâ”€â”€ select_batch_random() - Random selection with seed
â”‚   â”‚   â”œâ”€â”€ Filter: unlabeled = df[~df["id"].isin(labeled_ids)]
â”‚   â”‚   â””â”€â”€ Return batch DataFrame with selected records
â”‚   â”‚
â”‚   â”œâ”€â”€ classify_batch_with_api()
â”‚   â”‚   â”œâ”€â”€ core.labeling.prompt_builder: create_system_message_with_examples()
â”‚   â”‚   â”‚   â”œâ”€â”€ Load existing examples from master labels
â”‚   â”‚   â”‚   â”œâ”€â”€ Create definitions from config.settings: LABEL_INFO
â”‚   â”‚   â”‚   â”œâ”€â”€ Add recent examples to prompt (configurable max)
â”‚   â”‚   â”‚   â””â”€â”€ Return system message with few-shot examples
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ For each text in batch:
â”‚   â”‚   â”‚   â”œâ”€â”€ Call OpenAI API with system message + user text
â”‚   â”‚   â”‚   â”œâ”€â”€ Use JSON schema from config.settings: SCHEMA
â”‚   â”‚   â”‚   â”œâ”€â”€ Parse response to get category predictions (0/1)
â”‚   â”‚   â”‚   â””â”€â”€ Append to records list
â”‚   â”‚   â””â”€â”€ Return predictions + model name
â”‚   â”‚
â”‚   â””â”€â”€ Save batch file for manual correction
```

**Output:** 
- New MANUAL_LABEL_METHOD_AT-*.json file for manual correction
- Updated outputs/api_predictions.json with raw API predictions
- Instructions to manually correct the TO_LABEL file

---

### Option 3: Update master labels after corrections

**Purpose:** Process manually corrected labels and add them to the training dataset.

**Functions Called:**
```
main.py: Menu Option 3 Handler
â”œâ”€â”€ List available MANUAL_LABEL files in outputs/manual_labeling/batches/
â”œâ”€â”€ User selection (single file or ALL files)
â”‚
â””â”€â”€ core.labeling.label_manager.update_master_labels(file_path)
    â”œâ”€â”€ **Purpose:** Integrate corrected batch into master training dataset
    â”œâ”€â”€ **Args:** file_path: str - Path to corrected MANUAL_LABEL file
    â”œâ”€â”€ **Returns:** list - Updated master labels dataset
    â”œâ”€â”€ **Process:**
    â”‚   â”œâ”€â”€ Load corrected batch file (JSON format)
    â”‚   â”œâ”€â”€ Load existing master labels from outputs/manual_labeling/master/TOTAL_MANUAL_LABEL_*.json
    â”‚   â”œâ”€â”€ Merge new corrections with existing (deduplicate by ID)
    â”‚   â”œâ”€â”€ Save consolidated master labels
    â”‚   â”‚
    â”‚   â””â”€â”€ Generate fine-tuning dataset:
    â”‚       â”œâ”€â”€ core.labeling.prompt_builder.create_system_message_with_examples()
    â”‚       â”œâ”€â”€ For each labeled example:
    â”‚       â”‚   â”œâ”€â”€ Create OpenAI training format (system, user, assistant)
    â”‚       â”‚   â””â”€â”€ Append to JSONL training data
    â”‚       â””â”€â”€ Save outputs/fine_tuning/ft_data.jsonl
    â”‚
    â””â”€â”€ **Batch Processing Option:**
        â”œâ”€â”€ Process ALL files automatically
        â”œâ”€â”€ Sort files chronologically by timestamp
        â””â”€â”€ Sequential processing maintaining data integrity
```

**Output Files:**
- **Location:** `outputs/manual_labeling/master/`
- **Format:** JSON and JSONL
- **Files:**
  - `TOTAL_MANUAL_LABEL_AT-TIMESTAMP_TOTAL_SAMPLE_SIZE_N.json` - Master training dataset
  - `outputs/fine_tuning/training/ft_data.jsonl` - OpenAI fine-tuning format
- **Content:** Human-corrected labels ready for model training

---

### Option 4: Fine-tuning operations

**Purpose:** Comprehensive model fine-tuning, evaluation, and bulk classification operations.

**Functions Called:**
```
core.utils.menu_handlers.run_fine_tuning_menu(consolidated_df)
â”œâ”€â”€ **Sub-Option 1:** Estimate fine-tuning cost
â”‚   â””â”€â”€ core.models.fine_tuning.estimate_fine_tuning_cost()
â”‚       â”œâ”€â”€ **Purpose:** Calculate OpenAI fine-tuning costs
â”‚       â”œâ”€â”€ **Args:** None (reads from ft_data.jsonl)
â”‚       â””â”€â”€ **Returns:** Cost estimation display
â”‚
â”œâ”€â”€ **Sub-Option 2:** Upload training data and start fine-tuning
â”‚   â”œâ”€â”€ core.models.fine_tuning.upload_training_file(client)
â”‚   â”‚   â”œâ”€â”€ **Purpose:** Upload JSONL to OpenAI
â”‚   â”‚   â”œâ”€â”€ **Args:** client: OpenAI - API client
â”‚   â”‚   â””â”€â”€ **Returns:** str - File ID for training
â”‚   â”‚
â”‚   â””â”€â”€ core.models.fine_tuning.create_fine_tune_job(client, file_id, **params)
â”‚       â”œâ”€â”€ **Purpose:** Start OpenAI fine-tuning job
â”‚       â”œâ”€â”€ **Args:** client, file_id, epochs, batch_size, learning_rate_multiplier, suffix
â”‚       â””â”€â”€ **Returns:** Job object with job.id
â”‚
â”œâ”€â”€ **Sub-Option 3:** Check fine-tuning job status
â”‚   â””â”€â”€ core.models.fine_tuning.check_fine_tune_status(client, job_id)
â”‚       â”œâ”€â”€ **Purpose:** Monitor training progress
â”‚       â”œâ”€â”€ **Args:** client: OpenAI, job_id: str
â”‚       â””â”€â”€ **Returns:** str - Model name if completed
â”‚
â”œâ”€â”€ **Sub-Option 4:** List all fine-tuning jobs
â”‚   â””â”€â”€ core.models.fine_tuning.list_fine_tune_jobs(client)
â”‚       â”œâ”€â”€ **Purpose:** Display all training jobs and status
â”‚       â”œâ”€â”€ **Args:** client: OpenAI
â”‚       â””â”€â”€ **Returns:** Formatted job listing
â”‚
â”œâ”€â”€ **Sub-Option 5:** Test fine-tuned model
â”‚   â””â”€â”€ core.models.evaluation.test_fine_tuned_model(model_name, client)
â”‚       â”œâ”€â”€ **Purpose:** Evaluate model against manual labels
â”‚       â”œâ”€â”€ **Args:** model_name: str, client: OpenAI
â”‚       â””â”€â”€ **Returns:** tuple(stats: dict, accuracy: float)
â”‚
â”œâ”€â”€ **Sub-Option 6:** Bulk classify unlabeled data
â”‚   â””â”€â”€ core.models.bulk_classifier.run_bulk_classification(client, model_name, df, batch_size, include_manual)
â”‚       â”œâ”€â”€ **Purpose:** Apply model to large datasets
â”‚       â”œâ”€â”€ **Args:** client, model_name: str, df: DataFrame, batch_size: int, include_manual: bool
â”‚       â”œâ”€â”€ **Returns:** tuple(file_path: str, predictions: list, source_tracking: dict)
â”‚       â””â”€â”€ **Process:**
â”‚           â”œâ”€â”€ Filter unlabeled records (or all if include_manual=True)
â”‚           â”œâ”€â”€ Batch processing with progress tracking
â”‚           â”œâ”€â”€ Apply fine-tuned model predictions
â”‚           â””â”€â”€ Save timestamped results file
â”‚
â””â”€â”€ **Sub-Option 7:** Model performance comparison
    â”œâ”€â”€ core.models.evaluation.test_api_performance_baseline(client)
    â”œâ”€â”€ core.models.evaluation.test_api_performance_leave_one_out(client)
    â””â”€â”€ core.models.evaluation.compare_api_vs_manual_corrections()
```

**Output Files:**
- **Location:** `outputs/fine_tuning/`
- **Format:** JSONL for training, JSON for results
- **Files:**
  - `ft_data.jsonl` - OpenAI training format
  - `bulk_classification/BULK_model-name_YYYY-MM-DD_HHMMSS.json` - Classification results
- **Content:** Model training data and bulk classification results

---

### Option 5: Excel export & manual editing

**Purpose:** Export classifications to Excel for manual review and import changes back to system.

**Functions Called:**
```
core.utils.menu_handlers.run_excel_export_menu()
â”œâ”€â”€ **Sub-Option 1:** Export latest bulk results to Excel
â”‚   â””â”€â”€ core.utils.excel_export.export_latest_bulk_results(include_manual_labels=False)
â”‚       â”œâ”€â”€ **Purpose:** Convert bulk classification JSON to Excel
â”‚       â”œâ”€â”€ **Args:** include_manual_labels: bool
â”‚       â”œâ”€â”€ **Returns:** str - Excel file path
â”‚       â””â”€â”€ **Features:** RTL layout, freeze panes, formatted columns
â”‚
â”œâ”€â”€ **Sub-Option 2:** Export bulk + manual labels combined
â”‚   â””â”€â”€ core.utils.excel_export.export_latest_bulk_results(include_manual_labels=True)
â”‚       â”œâ”€â”€ **Purpose:** Merge bulk predictions with manual corrections
â”‚       â”œâ”€â”€ **Args:** include_manual_labels=True
â”‚       â”œâ”€â”€ **Returns:** str - Excel file path
â”‚       â””â”€â”€ **Features:** Source column shows manual vs model classifications
â”‚
â”œâ”€â”€ **Sub-Option 3:** Export manual labels only
â”‚   â””â”€â”€ core.utils.excel_export.export_manual_labels()
â”‚       â”œâ”€â”€ **Purpose:** Export only human-corrected labels
â”‚       â”œâ”€â”€ **Args:** None
â”‚       â”œâ”€â”€ **Returns:** str - Excel file path
â”‚       â””â”€â”€ **Content:** Pure manual corrections from master labels
â”‚
â”œâ”€â”€ **Sub-Option 4:** Export custom JSON file
â”‚   â””â”€â”€ core.utils.excel_export.convert_json_to_excel_rtl(json_path, output_path, include_manual)
â”‚       â”œâ”€â”€ **Purpose:** Convert any JSON classification file to Excel
â”‚       â”œâ”€â”€ **Args:** json_path: str, output_path: str, include_manual: bool
â”‚       â”œâ”€â”€ **Returns:** str - Excel file path
â”‚       â””â”€â”€ **Features:** Flexible JSON to Excel conversion
â”‚
â””â”€â”€ **Sub-Option 5:** Process Excel changes back to JSON
    â””â”€â”€ core.utils.change_detection.process_excel_changes(original_json, excel_path, integrate)
        â”œâ”€â”€ **Purpose:** Import Excel edits back to classification system
        â”œâ”€â”€ **Args:** original_json: str, excel_path: str, integrate: bool
        â”œâ”€â”€ **Returns:** tuple(changes_json: str, master_file: str)
        â””â”€â”€ **Process:**
            â”œâ”€â”€ Compare original JSON vs modified Excel
            â”œâ”€â”€ Detect classification changes
            â”œâ”€â”€ Generate change report
            â””â”€â”€ Optionally integrate with master labels system
```

**Output Files:**
- **Location:** `outputs/excel_exports/`
- **Format:** Excel (.xlsx) and JSON
- **Files:**
  - `bulk_results_YYYY-MM-DD_HHMMSS.xlsx` - Bulk classifications
  - `manual_labels_YYYY-MM-DD_HHMMSS.xlsx` - Manual corrections
  - `changes_YYYY-MM-DD_HHMMSS.json` - Change detection results
- **Features:** RTL support, color coding, source tracking, freeze panes

---

### Option 6: Project utilities

**Purpose:** Project status monitoring, file maintenance, and system diagnostics.

**Functions Called:**
```
core.utils.menu_handlers.run_project_utilities_menu()
â”œâ”€â”€ **Sub-Option 1:** Print project status
â”‚   â””â”€â”€ core.utils.project_status.print_project_status()
â”‚       â”œâ”€â”€ **Purpose:** Display comprehensive project statistics
â”‚       â”œâ”€â”€ **Args:** None
â”‚       â”œâ”€â”€ **Returns:** Console output with statistics
â”‚       â””â”€â”€ **Displays:**
â”‚           â”œâ”€â”€ Data files count and sizes
â”‚           â”œâ”€â”€ Manual labels progress
â”‚           â”œâ”€â”€ Batch processing history
â”‚           â”œâ”€â”€ Fine-tuning dataset statistics
â”‚           â””â”€â”€ Recent file activity
â”‚
â”œâ”€â”€ **Sub-Option 2:** Cleanup old files
â”‚   â””â”€â”€ core.utils.file_ops.cleanup_old_files(keep)
â”‚       â”œâ”€â”€ **Purpose:** Remove old batch files to free disk space
â”‚       â”œâ”€â”€ **Args:** keep: int - Number of recent files to preserve
â”‚       â”œâ”€â”€ **Returns:** Cleanup summary
â”‚       â””â”€â”€ **Process:**
â”‚           â”œâ”€â”€ Identify old TO_LABEL and batch files
â”‚           â”œâ”€â”€ Preserve specified number of recent files
â”‚           â”œâ”€â”€ Remove outdated temporary files
â”‚           â””â”€â”€ Report space freed
â”‚
â””â”€â”€ **Sub-Option 3:** Export progress report
    â””â”€â”€ core.utils.project_status.export_progress_report()
        â”œâ”€â”€ **Purpose:** Generate detailed project progress report
        â”œâ”€â”€ **Args:** None
        â”œâ”€â”€ **Returns:** str - Report file path
        â””â”€â”€ **Content:**
            â”œâ”€â”€ Classification accuracy trends
            â”œâ”€â”€ Data processing timeline
            â”œâ”€â”€ Model performance metrics
            â””â”€â”€ File system status
```

**Output Files:**
- **Location:** `outputs/reports/`
- **Format:** JSON and text reports
- **Files:**
  - `progress_report_YYYY-MM-DD_HHMMSS.json` - Detailed metrics
  - `project_status.txt` - Human-readable summary
- **Content:** Project statistics, file counts, accuracy trends, system health

---

### Option 0: Exit

**Purpose:** Gracefully exit the application, ensuring all data is properly saved and connections are closed.

---

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ main.py                    # Interactive menu system
â”‚   â”œâ”€â”€ main() -> None                           # Main menu loop
â”‚   â”œâ”€â”€ print_manual_prompt() -> None            # Manual labeling prompt display
â”‚   â””â”€â”€ ensure_directories() -> None             # Directory structure validation
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies (55 packages)
â”œâ”€â”€ .env.example              # Environment configuration template
â”œâ”€â”€ .gitignore                # Git ignore rules (exclude all, allow .py)
â”œâ”€â”€ README.md                 # Project documentation
â”‚
â”œâ”€â”€ config/                   # Configuration modules
â”‚   â”œâ”€â”€ settings.py          # Settings loaded from environment
â”‚   â”‚   â”œâ”€â”€ get_system_prompt() -> str            # Dynamic system prompt builder
â”‚   â”‚   â”œâ”€â”€ get_prompt(prompt_type, **kwargs) -> str # Get formatted prompt template
â”‚   â”‚   â””â”€â”€ Environment Variables: OPENAI_API_KEY, COLUMN_MAPPINGS, FILES, LABEL_INFO, PROMPTS
â”‚   â”‚
â”‚   â””â”€â”€ paths.py             # File path configurations
â”‚       â”œâ”€â”€ ensure_directories() -> None          # Create required directories
â”‚       â””â”€â”€ PATHS: dict                          # Central path configuration
â”‚
â”œâ”€â”€ core/                    # Core application modules
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                # Data processing modules
â”‚   â”‚   â”œâ”€â”€ anonymizer.py    # Data anonymization functions
â”‚   â”‚   â”‚   â”œâ”€â”€ anonymize_data(dfs: dict) -> dict            # Main anonymization orchestrator
â”‚   â”‚   â”‚   â”œâ”€â”€ anonymize_national_id(text: str) -> str      # Replace ID numbers with sequential digits
â”‚   â”‚   â”‚   â”œâ”€â”€ anonymize_phone_numbers(text: str) -> str    # Standardize phone format
â”‚   â”‚   â”‚   â””â”€â”€ anonymize_names_from_excel(text: str) -> str # Replace names with placeholders
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ loader.py        # Data loading and consolidation
â”‚   â”‚       â”œâ”€â”€ load_data() -> dict                          # Load Excel files with column mapping
â”‚   â”‚       â”œâ”€â”€ consolidate_data(all_df: dict) -> DataFrame  # Merge DataFrames with deduplication
â”‚   â”‚       â””â”€â”€ (No additional validation functions)
â”‚   â”‚
â”‚   â”œâ”€â”€ labeling/            # Labeling workflow modules
â”‚   â”‚   â”œâ”€â”€ batch_processor.py    # Batch selection and API calls
â”‚   â”‚   â”‚   â”œâ”€â”€ process_batch_for_labeling(df, labeled_ids, client, batch_size, selection_method, max_examples) -> tuple
â”‚   â”‚   â”‚   â”œâ”€â”€ select_batch_by_length(df, labeled_ids, batch_size=10) -> DataFrame
â”‚   â”‚   â”‚   â”œâ”€â”€ select_batch_by_shortest(df, labeled_ids, batch_size=10) -> DataFrame
â”‚   â”‚   â”‚   â”œâ”€â”€ select_batch_by_medium_length(df, labeled_ids, batch_size=10) -> DataFrame
â”‚   â”‚   â”‚   â”œâ”€â”€ select_batch_random(df, labeled_ids, batch_size=10, random_state=42) -> DataFrame
â”‚   â”‚   â”‚   â””â”€â”€ classify_batch_with_api(batch, client, model, max_examples) -> tuple
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ label_manager.py      # Label management and ID creation
â”‚   â”‚   â”‚   â”œâ”€â”€ prepare_for_labeling(df: DataFrame) -> tuple  # Add stable IDs, load existing labels
â”‚   â”‚   â”‚   â”œâ”€â”€ create_stable_ids(df: DataFrame) -> DataFrame # Generate MD5 hash IDs from content
â”‚   â”‚   â”‚   â”œâ”€â”€ load_labeled_ids() -> set                    # Extract already labeled ID set
â”‚   â”‚   â”‚   â””â”€â”€ update_master_labels(file_path: str) -> list # Integrate corrections into training dataset
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ prompt_builder.py     # Few-shot prompt creation
â”‚   â”‚       â”œâ”€â”€ create_system_message_with_examples(max_examples: int) -> str # Build few-shot system prompt
â”‚   â”‚       â”œâ”€â”€ load_existing_examples() -> list             # Load training examples from master labels
â”‚   â”‚       â””â”€â”€ format_examples_for_prompt(examples: list) -> str # Format examples for API prompt
â”‚   â”‚
â”‚   â”œâ”€â”€ models/              # Model and evaluation modules
â”‚   â”‚   â”œâ”€â”€ bulk_classifier.py    # Bulk classification functionality
â”‚   â”‚   â”‚   â”œâ”€â”€ run_bulk_classification(client, model_name, df, batch_size, include_manual) -> tuple
â”‚   â”‚   â”‚   â”œâ”€â”€ filter_unlabeled_data(df, include_manual) -> DataFrame
â”‚   â”‚   â”‚   â””â”€â”€ batch_classify_with_progress(client, model_name, df, batch_size) -> list
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ evaluation.py         # Performance testing
â”‚   â”‚   â”‚   â”œâ”€â”€ test_api_performance_baseline(client) -> tuple        # No examples evaluation
â”‚   â”‚   â”‚   â”œâ”€â”€ test_api_performance_leave_one_out(client) -> tuple   # Fair few-shot testing
â”‚   â”‚   â”‚   â”œâ”€â”€ compare_api_vs_manual_corrections() -> tuple          # Original vs corrected comparison
â”‚   â”‚   â”‚   â””â”€â”€ test_fine_tuned_model(model_name, client) -> tuple    # Fine-tuned model evaluation
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ fine_tuning.py        # Model fine-tuning
â”‚   â”‚       â”œâ”€â”€ upload_training_file(client) -> str                   # Upload JSONL to OpenAI
â”‚   â”‚       â”œâ”€â”€ create_fine_tune_job(client, file_id, **params) -> Job # Start fine-tuning job
â”‚   â”‚       â”œâ”€â”€ check_fine_tune_status(client, job_id) -> str         # Monitor training progress
â”‚   â”‚       â”œâ”€â”€ list_fine_tune_jobs(client) -> None                   # Display all jobs
â”‚   â”‚       â””â”€â”€ estimate_fine_tuning_cost() -> None                   # Calculate training costs
â”‚   â”‚
â”‚   â””â”€â”€ utils/               # Utility modules
â”‚       â”œâ”€â”€ change_detection.py   # File change monitoring
â”‚       â”‚   â””â”€â”€ process_excel_changes(original_json, excel_path, integrate) -> tuple
â”‚       â”‚
â”‚       â”œâ”€â”€ excel_export.py       # Excel export functionality
â”‚       â”‚   â”œâ”€â”€ export_latest_bulk_results(include_manual_labels) -> str
â”‚       â”‚   â”œâ”€â”€ export_manual_labels() -> str
â”‚       â”‚   â””â”€â”€ convert_json_to_excel_rtl(json_path, output_path, include_manual) -> str
â”‚       â”‚
â”‚       â”œâ”€â”€ file_ops.py           # File operations
â”‚       â”‚   â””â”€â”€ cleanup_old_files(keep: int) -> None
â”‚       â”‚
â”‚       â”œâ”€â”€ menu_handlers.py      # Menu system handlers
â”‚       â”‚   â”œâ”€â”€ run_data_preparation() -> DataFrame
â”‚       â”‚   â”œâ”€â”€ run_single_labeling_batch(df, batch_size, selection_method, max_examples) -> str
â”‚       â”‚   â”œâ”€â”€ run_fine_tuning_menu(consolidated_df) -> None
â”‚       â”‚   â”œâ”€â”€ run_excel_export_menu() -> None
â”‚       â”‚   â””â”€â”€ run_project_utilities_menu() -> None
â”‚       â”‚
â”‚       â”œâ”€â”€ project_status.py     # Project status reporting
â”‚       â”‚   â”œâ”€â”€ print_project_status() -> None
â”‚       â”‚   â””â”€â”€ export_progress_report() -> str
â”‚       â”‚
â”‚       â””â”€â”€ tree_logger.py        # Logging utilities
â”‚           â”œâ”€â”€ log(msg: str) -> None
â”‚           â””â”€â”€ print_tree(node: str, prefix: str) -> None
â”‚
â””â”€â”€ outputs/                 # Generated files (git-ignored)
    â”œâ”€â”€ bulk_classification/ # Bulk processing results
    â”‚   â””â”€â”€ BULK_model-name_YYYY-MM-DD_HHMMSS.json
    â”‚
    â”œâ”€â”€ fine_tuning/         # Fine-tuning datasets
    â”‚   â””â”€â”€ ft_data.jsonl    # OpenAI training format
    â”‚
    â”œâ”€â”€ manual_labeling/     # Manual labeling batches
    â”‚   â”œâ”€â”€ batches/         # Individual batch files
    â”‚   â”‚   â””â”€â”€ MANUAL_LABEL_METHOD_AT-YYYYMMDD_HHMMSS_*.json
    â”‚   â””â”€â”€ master/          # Consolidated labeled data
    â”‚       â””â”€â”€ TOTAL_MANUAL_LABEL_AT-TIMESTAMP_TOTAL_SAMPLE_SIZE_N.json # Master training dataset
    â”‚
    â”œâ”€â”€ excel_exports/       # Excel export files
    â”‚   â”œâ”€â”€ bulk_results_*.xlsx
    â”‚   â””â”€â”€ manual_labels_*.xlsx
    â”‚
    â””â”€â”€ reports/            # Project status reports
        â””â”€â”€ progress_report_*.json
```

## Key Features

- **Progressive Few-Shot Learning:** Each corrected batch improves future predictions
- **Stable Content-Based IDs:** MD5 hashes ensure consistent identification
- **Comprehensive Evaluation:** Baseline, leave-one-out, and correction comparison tests
- **Data Separation:** Raw predictions and corrected labels stored separately
- **Modular Design:** Each function has single responsibility
- **Memory-Based Workflow:** DataFrames persist in memory, no unnecessary file I/O

## ğŸ¯ Usage

### Basic Workflow

1. **Setup Environment**
   ```bash
   python main.py
   ```
   
2. **Data Preparation** (Option 1)
   - Load and anonymize your data files
   - Consolidate into a unified dataset
   
3. **Interactive Labeling** (Option 2)
   - Generate API predictions for unlabeled batches
   - Manually correct predictions using human expertise
   
4. **Master Label Updates** (Option 3)
   - Incorporate corrections into training dataset
   - System learns from your feedback
   
5. **Model Operations** (Option 4)
   - Fine-tune models with accumulated labeled data
   - Evaluate performance improvements
   
6. **Bulk Processing** (Option 5)
   - Apply trained models to large datasets
   - Export results for analysis

### Human-in-the-Loop Process

The system implements a continuous improvement cycle:
1. **Initial predictions** from base model
2. **Human corrections** improve training data
3. **Progressive learning** from accumulated feedback
4. **Better predictions** for future batches

## ğŸ“Š Key Features

- **ğŸ”„ Progressive Learning**: Each correction improves future predictions
- **ğŸ·ï¸ Human-in-the-Loop**: Combines AI efficiency with human expertise
- **ğŸ” Data Privacy**: Environment-based configuration keeps sensitive data secure
- **ğŸ“ˆ Evaluation Suite**: Comprehensive testing and performance metrics
- **ğŸš€ Bulk Processing**: Scale to thousands of records efficiently
- **ğŸ›¡ï¸ Data Anonymization**: Built-in PII protection
- **ğŸ“‹ Interactive Interface**: User-friendly menu system